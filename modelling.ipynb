{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kshitiz\n",
      "[nltk_data]     sharan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import regularizers\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>dr. goldberg offers everything i look for in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Got a letter in the mail last week that said D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               Text\n",
       "0      5  dr. goldberg offers everything i look for in a...\n",
       "1      2  Unfortunately, the frustration of being Dr. Go...\n",
       "2      4  Been going to Dr. Goldberg for over 10 years. ...\n",
       "3      4  Got a letter in the mail last week that said D...\n",
       "4      1  I don't know what Dr. Goldberg was like before..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file='./train1.csv'\n",
    "data=pd.read_csv(data_file)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x<3:\n",
    "        return 'negative'\n",
    "    return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualScore_train=data['score']\n",
    "positiveNegative=actualScore_train.map(partition)\n",
    "data['score']=positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gt'] = data['score'].map({'negative':0,'positive':1})\n",
    "\n",
    "data['Text']=data['Text'].map(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(data.Text.unique())\n",
    "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650000, 650000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=32\n",
    "sentences=data['Text']\n",
    "labels=data['gt']\n",
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goldberg',\n",
       " 'offers',\n",
       " 'everything',\n",
       " 'look',\n",
       " 'general',\n",
       " 'practitioner',\n",
       " 'nice',\n",
       " 'easy',\n",
       " 'talk',\n",
       " 'without',\n",
       " 'patron',\n",
       " '##izing',\n",
       " 'always',\n",
       " 'time',\n",
       " 'seeing',\n",
       " 'patients',\n",
       " 'affiliated',\n",
       " 'top',\n",
       " 'notch',\n",
       " 'hospital',\n",
       " 'nyu',\n",
       " 'parents',\n",
       " 'explained',\n",
       " 'important',\n",
       " 'case',\n",
       " 'something',\n",
       " 'happens',\n",
       " 'need',\n",
       " 'surgery',\n",
       " 'get',\n",
       " 'refer',\n",
       " '##ral',\n",
       " '##s',\n",
       " 'see',\n",
       " 'specialists',\n",
       " 'without',\n",
       " 'see',\n",
       " 'first',\n",
       " 'really',\n",
       " 'need',\n",
       " 'sitting',\n",
       " 'trying',\n",
       " 'think',\n",
       " 'complaints',\n",
       " 'really',\n",
       " 'drawing',\n",
       " 'blank']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 18522, 4107, 2673, 2298, 2236, 18742, 3835, 3733, 2831, 2302, 9161, 6026, 2467, 2051, 3773, 5022, 6989, 2327, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp=dbert_tokenizer.encode_plus(sentences[0],add_special_tokens = True,max_length =20,pad_to_max_length = True,truncation=True)\n",
    "dbert_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 18522,\n",
       " 4107,\n",
       " 2673,\n",
       " 2298,\n",
       " 2236,\n",
       " 18742,\n",
       " 3835,\n",
       " 3733,\n",
       " 2831,\n",
       " 2302,\n",
       " 9161,\n",
       " 6026,\n",
       " 2467,\n",
       " 2051,\n",
       " 3773,\n",
       " 5022,\n",
       " 6989,\n",
       " 2327,\n",
       " 102]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.modeling_tf_outputs.TFBaseModelOutput,\n",
       " TFBaseModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 20, 768), dtype=float32, numpy=\n",
       " array([[[-1.98320448e-01,  3.00513357e-02,  1.59358427e-01, ...,\n",
       "          -1.69523388e-01,  4.42057252e-01,  1.07091025e-01],\n",
       "         [ 2.34363168e-01,  4.54131216e-02,  9.03326496e-02, ...,\n",
       "           5.73578440e-02,  1.72908157e-01,  2.74978667e-01],\n",
       "         [-3.47497255e-01,  2.88471729e-01,  3.91802549e-01, ...,\n",
       "          -2.27810785e-01,  2.29090795e-01, -1.70055494e-01],\n",
       "         ...,\n",
       "         [ 2.42646620e-01,  1.87672615e-01,  3.72264087e-01, ...,\n",
       "           1.08914450e-04,  1.46245599e-01, -1.59351721e-01],\n",
       "         [-3.69360335e-02,  6.71055168e-02,  8.68291110e-02, ...,\n",
       "           1.13608122e-01,  3.42743218e-01, -4.49185669e-01],\n",
       "         [ 7.01780379e-01,  2.64715254e-01, -3.71728539e-01, ...,\n",
       "           7.89778829e-02, -4.27991748e-01, -2.50801206e-01]]],\n",
       "       dtype=float32)>, hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_inp=np.asarray(dbert_inp['input_ids'])\n",
    "mask_inp=np.asarray(dbert_inp['attention_mask'])\n",
    "out=dbert_model([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\n",
    "type(out),out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-1.98320448e-01,  3.00513357e-02,  1.59358427e-01,\n",
       "        -1.54239729e-01,  4.71313633e-02, -8.48967433e-02,\n",
       "         3.48035991e-01,  3.43655705e-01, -7.00134486e-02,\n",
       "        -3.34983110e-01,  1.90282896e-01, -1.33307323e-01,\n",
       "         2.04382807e-01,  2.77472168e-01, -1.21448442e-01,\n",
       "         2.54669219e-01,  1.14152081e-01,  2.88363129e-01,\n",
       "         1.48429453e-01, -1.32481694e-01,  4.83718403e-02,\n",
       "        -6.26427710e-01,  2.55077124e-01, -1.39423832e-01,\n",
       "        -5.51867485e-03,  8.52848589e-03, -4.97719944e-02,\n",
       "        -2.30354980e-01, -4.35163788e-02,  1.69881523e-01,\n",
       "         1.70469880e-01,  1.27865836e-01, -8.48859549e-03,\n",
       "        -3.59298974e-01,  1.43056065e-01, -9.18514654e-02,\n",
       "         3.07672590e-01,  2.68631309e-01, -7.78873563e-02,\n",
       "         1.63533799e-02, -1.18057154e-01,  1.11377575e-02,\n",
       "         3.44903141e-01, -1.88439608e-01,  5.97983412e-02,\n",
       "        -2.17247829e-01, -2.53238463e+00, -3.55465353e-01,\n",
       "         5.04067317e-02, -2.35091224e-01,  2.15059936e-01,\n",
       "        -1.17257759e-01,  9.48973149e-02,  2.68496186e-01,\n",
       "         7.33081028e-02,  3.59876454e-01, -2.39112616e-01,\n",
       "         2.89659560e-01, -4.40757908e-02,  1.15469962e-01,\n",
       "         2.04795375e-02,  2.81469002e-02, -1.70614839e-01,\n",
       "         5.99182509e-02, -8.34991932e-02,  2.04705283e-01,\n",
       "        -2.55842239e-01,  1.41155601e-01, -3.29965711e-01,\n",
       "         4.60684866e-01, -1.86545908e-01, -2.39455521e-01,\n",
       "         3.84501576e-01, -1.02569073e-01,  3.70062813e-02,\n",
       "         2.32177600e-02, -4.89919335e-02,  1.50189057e-01,\n",
       "         8.79328027e-02, -4.48841155e-02,  1.72044709e-03,\n",
       "         1.33700743e-01,  1.26384422e-01,  2.88710356e-01,\n",
       "         3.12879086e-02,  2.83483595e-01, -3.64369005e-02,\n",
       "        -6.45088479e-02,  1.54175013e-01,  5.30884802e-01,\n",
       "        -3.30073759e-04, -1.42903239e-01,  2.12833554e-01,\n",
       "        -7.26918504e-02,  1.71919242e-01, -2.94686407e-01,\n",
       "         2.01048762e-01, -9.58539993e-02,  1.85051963e-01,\n",
       "         2.24165291e-01,  1.01274773e-01, -4.09910642e-03,\n",
       "         5.12542166e-02, -3.57798159e-01,  1.24699324e-01,\n",
       "        -4.30304334e-02,  6.83019161e-02, -1.62177116e-01,\n",
       "        -1.16224587e-01, -1.59656000e+00, -1.93317071e-01,\n",
       "         4.88833860e-02,  3.67004424e-04, -1.97785944e-01,\n",
       "        -3.55597526e-01,  4.36054975e-01,  1.86072350e-01,\n",
       "         5.54824583e-02,  6.81177974e-02, -1.35848016e-01,\n",
       "         6.69888780e-02,  4.12912250e-01,  9.85723808e-02,\n",
       "         1.05927959e-01,  1.03262048e-02,  1.25072405e-01,\n",
       "        -1.17343441e-01,  8.33484232e-02,  3.30931664e-01,\n",
       "         1.84573352e-01,  2.01991320e-01,  1.26544952e-01,\n",
       "        -2.94772536e-03, -4.58021984e-02, -1.39925003e-01,\n",
       "         2.73093432e-01,  2.69658536e-01, -2.18929410e-01,\n",
       "        -3.45460534e-01,  1.53423071e-01, -1.61007047e-01,\n",
       "        -4.28101830e-02, -2.28575921e+00,  2.22018212e-01,\n",
       "         5.09849429e-01, -1.65322796e-03,  2.49135345e-01,\n",
       "         3.71288285e-02, -1.18546747e-01,  1.18241131e-01,\n",
       "        -5.36844917e-02,  3.28389049e-01, -1.50291517e-01,\n",
       "        -1.44444719e-01, -1.24225274e-01,  1.49779454e-01,\n",
       "        -2.41027996e-01, -2.52553709e-02,  2.39652768e-01,\n",
       "         1.21432096e-01,  8.19743052e-02, -5.45593947e-02,\n",
       "         3.55368853e-02, -1.11408941e-01, -1.01408549e-01,\n",
       "         8.32187682e-02, -4.45589274e-02, -1.37616932e-01,\n",
       "        -9.46101993e-02, -5.25434501e-04, -1.16197057e-01,\n",
       "         2.59084523e-01,  7.58867711e-02, -2.99042761e-01,\n",
       "         4.07230526e-01,  9.49920118e-02,  1.26836583e-01,\n",
       "         1.45677075e-01, -2.51892179e-01, -7.28422180e-02,\n",
       "        -1.87222779e-01,  3.35276425e-01, -3.76600772e-02,\n",
       "        -8.95438716e-02,  2.00204179e-01, -4.29444313e-01,\n",
       "         2.71894723e-01,  1.78375304e-01,  2.57842392e-01,\n",
       "         2.28378266e-01,  5.45801781e-02,  4.09571007e-02,\n",
       "         1.19863957e-01,  1.54844567e-01,  2.61165380e-01,\n",
       "         1.60743997e-01,  3.15697268e-02, -2.56554306e-01,\n",
       "        -7.53215998e-02, -8.07639658e-02,  1.91771276e-02,\n",
       "         7.09636956e-02, -2.84232199e-01,  2.04842240e-01,\n",
       "        -4.42127943e-01,  3.07766747e+00,  1.05631620e-01,\n",
       "        -8.71525034e-02,  1.81622833e-01,  2.86126316e-01,\n",
       "         1.65850669e-01,  1.54438876e-02, -1.46499619e-01,\n",
       "        -1.10097297e-01,  2.22739220e-01,  7.91192502e-02,\n",
       "         2.16572851e-01, -4.00645323e-02, -7.05865771e-02,\n",
       "         7.81046748e-02,  1.84955031e-01,  1.13103472e-01,\n",
       "        -2.52149962e-02,  3.90717208e-01, -8.72696936e-02,\n",
       "         7.24275857e-02,  5.86227477e-02, -1.90123260e-01,\n",
       "        -1.53664291e-01, -8.00781608e-01,  1.85736209e-01,\n",
       "        -2.43902460e-01,  1.94488406e-01,  4.36813794e-02,\n",
       "        -1.90877214e-01,  1.64967805e-01, -5.46113886e-02,\n",
       "        -6.75438792e-02,  8.22637230e-02, -1.87266096e-01,\n",
       "        -1.72959134e-01,  5.82258701e-02,  1.35276571e-01,\n",
       "         1.19943269e-01, -3.11410725e-02,  1.78806812e-01,\n",
       "        -1.18828796e-01, -1.23175167e-01, -2.29633749e-02,\n",
       "        -2.39747852e-01, -3.44607644e-02, -1.82351992e-02,\n",
       "         1.52889445e-01, -6.29797205e-02,  2.68593788e-01,\n",
       "        -4.29381430e-03,  1.47971034e-01,  2.24645287e-01,\n",
       "        -2.59188592e-01, -1.35597870e-01, -1.95437580e-01,\n",
       "         1.22624010e-01,  1.33834109e-01,  4.56293747e-02,\n",
       "        -2.92324513e-01, -2.11489975e-01, -4.08492163e-02,\n",
       "        -8.69520679e-02,  1.02730811e-01, -1.12512559e-01,\n",
       "        -1.41858980e-01, -3.69069725e-03, -3.81941617e-01,\n",
       "        -2.77175546e+00, -1.03193201e-01, -2.06573069e-01,\n",
       "         9.32384431e-02,  3.87114555e-01,  2.73684353e-01,\n",
       "         3.12234089e-02,  2.67482579e-01,  1.93932086e-01,\n",
       "         4.66598906e-02,  3.18556845e-01,  1.65087700e-01,\n",
       "        -7.84675702e-02,  9.07608122e-02, -5.17008483e-01,\n",
       "        -3.66119742e-02, -6.42655790e-02, -8.66958275e-02,\n",
       "         2.04231605e-01, -1.16293885e-01, -1.00316957e-01,\n",
       "         2.62588382e-01, -1.27776533e-01,  1.36510357e-01,\n",
       "        -7.15672672e-02, -8.43242556e-02, -3.47234458e-01,\n",
       "        -1.98071301e-01,  1.03469372e-01,  3.39997292e-01,\n",
       "         6.03559762e-02, -1.21762440e-01,  5.54158259e-03,\n",
       "        -2.08764300e-01, -3.71836662e-01, -3.97877288e+00,\n",
       "        -5.03660925e-03, -1.47904500e-01, -1.25241697e-01,\n",
       "         2.22650290e-01, -2.87804574e-01,  3.57364565e-01,\n",
       "        -1.17081357e-02, -2.61137873e-01,  1.89034671e-01,\n",
       "         8.20250250e-04,  5.41791804e-02,  1.52970135e-01,\n",
       "         1.43127114e-01,  2.27820754e-01,  4.39625740e-01,\n",
       "         1.86182305e-01, -7.33932927e-02,  1.54479235e-01,\n",
       "         2.67385960e-01,  4.92497087e-02, -2.29628056e-01,\n",
       "         1.95607200e-01,  1.44437598e-02,  2.19389766e-01,\n",
       "         2.85891891e-01, -4.78065759e-01,  2.84568042e-01,\n",
       "        -4.27037060e-01, -1.36556670e-01,  1.96264498e-02,\n",
       "         3.92147638e-02, -2.47260123e-01,  5.68809286e-02,\n",
       "        -1.95650876e-01, -2.14357898e-01,  1.47161186e-01,\n",
       "         2.16488540e-02,  3.96580696e-01,  8.05179030e-02,\n",
       "        -2.66002677e-02,  4.59237814e-01,  6.93882257e-02,\n",
       "         2.02135742e-01,  5.77989817e-01,  1.10190377e-01,\n",
       "         1.49428457e-01, -7.96186775e-02,  7.28320926e-02,\n",
       "         1.49326444e-01, -1.25760883e-02, -1.79199219e-01,\n",
       "         9.32292879e-01, -6.62824884e-03, -1.86226293e-02,\n",
       "        -3.50636125e-01,  3.25169027e-01,  2.78354615e-01,\n",
       "        -1.48349598e-01,  1.42470002e-04,  2.89227724e-01,\n",
       "        -2.20188513e-01, -4.64503281e-03, -5.30949533e-02,\n",
       "         4.66761440e-02, -1.06680393e-01,  1.56740099e-01,\n",
       "        -4.12187666e-01, -9.28393081e-02, -4.49516624e-03,\n",
       "        -4.21320945e-02,  2.75362253e-01,  2.67812401e-01,\n",
       "        -9.41587687e-01, -1.25278095e-02, -1.68479979e-02,\n",
       "         5.01237661e-02,  7.13154078e-02, -2.37021353e-02,\n",
       "         8.51175487e-02, -7.82559961e-02, -1.00280941e-02,\n",
       "        -7.07328320e-02,  1.71339855e-01, -2.30269164e-01,\n",
       "        -2.17193097e-01, -7.42764845e-02,  1.43855155e-01,\n",
       "        -5.06558776e-01,  2.66457826e-01, -1.67019382e-01,\n",
       "         2.17941999e-01,  2.47100383e-01,  1.41534522e-01,\n",
       "        -3.08592953e-02,  5.21985441e-03,  3.39084089e-01,\n",
       "        -6.82541668e-01,  5.46137989e-03, -1.78479135e-01,\n",
       "         1.93807557e-01, -1.56306595e-01, -9.55639780e-03,\n",
       "         4.23497818e-02, -1.74295306e-01, -6.35459423e-02,\n",
       "        -1.11182660e-01,  7.94831514e-02,  1.33802682e-01,\n",
       "         5.14006428e-02, -1.50409073e-01, -7.73207992e-02,\n",
       "        -1.29791468e-01,  3.33298147e-02,  8.04297686e-01,\n",
       "        -1.38800696e-01, -9.99423563e-02,  3.03994536e-01,\n",
       "        -3.69144417e-02,  1.04651324e-01,  9.52143520e-02,\n",
       "         6.51833192e-02,  4.76325005e-02,  2.12788582e-02,\n",
       "        -2.17275441e-01,  5.41451052e-02,  5.44009684e-03,\n",
       "        -8.63878876e-02, -3.96326095e-01,  3.12879860e-01,\n",
       "         5.79597149e-03, -9.70389247e-02,  1.15790423e-02,\n",
       "        -3.01681608e-01,  9.10091773e-02, -1.48292616e-01,\n",
       "        -4.03648540e-02,  1.00764997e-01,  2.42166489e-01,\n",
       "         8.72458518e-03,  2.08103031e-01,  2.10867837e-01,\n",
       "        -1.01639800e-01,  5.95731318e-01, -1.68629419e-02,\n",
       "         2.54399151e-01,  7.13710040e-02,  6.74162954e-02,\n",
       "        -4.97573726e-02,  2.21903875e-01, -1.91789046e-02,\n",
       "        -9.86728519e-02,  5.88764250e-02, -3.46614063e-01,\n",
       "         3.29431117e-01,  3.36830094e-02, -1.53533503e-01,\n",
       "        -1.22412078e-01, -2.16494367e-01, -1.16922140e-01,\n",
       "        -9.96943414e-02,  5.14917076e-03, -1.23209512e+00,\n",
       "         3.32090914e-01,  7.29523003e-02,  3.68216932e-02,\n",
       "        -1.46957025e-01, -8.38729441e-02, -1.80725843e-01,\n",
       "         3.63698542e-01,  1.65099591e-01,  1.74211696e-01,\n",
       "        -5.38744032e-02, -1.32864133e-01,  3.61583978e-02,\n",
       "         1.14258550e-01,  1.08472340e-01, -4.31942288e-03,\n",
       "         5.70340455e-03,  2.09141433e-01,  2.11466134e-01,\n",
       "        -2.89173752e-01, -2.19539195e-01,  4.75166470e-01,\n",
       "         3.70171249e-01, -1.32220954e-01,  5.60434535e-04,\n",
       "        -1.17903106e-01,  1.00378290e-01,  4.13078070e-01,\n",
       "         1.65636182e-01,  2.87061960e-01, -2.37190351e-01,\n",
       "        -1.16649009e-02, -3.73521417e-01, -2.81610340e-01,\n",
       "         3.26045841e-01,  2.27972031e-01,  1.59164801e-01,\n",
       "        -1.01590611e-01, -1.05682895e-01,  2.24851161e-01,\n",
       "        -4.07482177e-01,  4.20713872e-01,  1.01370141e-01,\n",
       "        -7.17456546e-03,  4.49307024e-01,  1.84754416e-01,\n",
       "        -1.81718320e-02,  2.10014030e-01,  3.53424326e-02,\n",
       "        -2.09813073e-01,  6.44908398e-02,  2.00145133e-02,\n",
       "        -9.33704451e-02, -2.02004224e-01, -2.59278357e-01,\n",
       "        -1.68039158e-01, -2.95228541e-01,  1.36910781e-01,\n",
       "         2.11753752e-02, -2.19177514e-01, -4.33006808e-02,\n",
       "        -9.36435238e-02, -1.60446137e-01,  2.41805106e-01,\n",
       "        -1.29267871e-01, -4.52508092e-01, -4.41098213e-02,\n",
       "        -1.36072993e-01, -6.39432594e-02, -1.15445629e-02,\n",
       "         2.30296910e-01, -1.49795607e-01, -1.89772338e-01,\n",
       "         2.87841082e-01, -3.46634924e-01,  1.47145495e-01,\n",
       "         1.31071851e-01, -1.20203577e-01, -2.72303492e-01,\n",
       "        -2.29243949e-01, -1.81329161e-01, -5.50517678e-01,\n",
       "        -1.68244481e-01,  4.27803487e-01, -1.61464199e-01,\n",
       "         2.66614631e-02, -6.72000125e-02,  1.04150839e-01,\n",
       "         1.03328973e-02, -8.02556798e-02,  3.27117778e-02,\n",
       "        -2.80264258e-01,  1.59903333e-01,  1.69293195e-01,\n",
       "         9.86863300e-02, -1.17287040e-01, -1.38044208e-01,\n",
       "        -3.24007720e-02, -1.64237007e-01,  9.44516957e-02,\n",
       "        -2.43704259e-01,  3.17524612e-01,  2.03980997e-01,\n",
       "         2.66161144e-01, -4.54599820e-02,  1.07854977e-01,\n",
       "        -1.63863655e-02, -1.03859544e-01, -2.78086126e-01,\n",
       "        -7.20759779e-02,  4.07947078e-02, -8.34460631e-02,\n",
       "        -8.14962834e-02,  1.28854573e-01, -3.40360142e-02,\n",
       "        -1.66240275e-01, -8.18260759e-03,  1.72515094e-01,\n",
       "         1.52236474e+00,  8.00406486e-02, -2.75477674e-02,\n",
       "         9.18679982e-02,  2.94620186e-01, -2.06822217e-01,\n",
       "        -1.67868912e-01,  2.36660197e-01, -7.42082968e-02,\n",
       "         4.46460575e-01, -1.66594312e-02,  1.35561340e-02,\n",
       "        -1.13259941e-01,  2.08275765e-01,  2.11177766e-01,\n",
       "         3.23582530e-01,  2.98101813e-01, -2.63167441e-01,\n",
       "        -1.42454058e-01,  1.16171651e-02, -3.57201755e-01,\n",
       "         2.04444349e-01,  3.04183722e-01,  1.18907452e-01,\n",
       "        -1.07690267e-01,  3.21859539e-01, -6.97113127e-02,\n",
       "        -3.20435673e-01,  1.60094038e-01,  1.05090797e-01,\n",
       "        -1.09209657e-01, -8.06162655e-02,  4.05122966e-01,\n",
       "         3.82408351e-01, -1.73017353e-01, -1.56992599e-01,\n",
       "        -6.37147501e-02, -7.85295069e-02, -1.54461116e-01,\n",
       "        -1.40669290e-03,  7.33261555e-02, -2.74281681e-01,\n",
       "         2.19147533e-01, -2.21728384e-02, -2.27589235e-01,\n",
       "         4.52527285e-01, -5.90094626e-02, -3.26829642e-01,\n",
       "         1.81245461e-01,  1.54607937e-01,  2.84135550e-01,\n",
       "         1.59103051e-01, -1.44241840e-01, -2.51779586e-01,\n",
       "        -1.09137120e-02, -7.88453147e-02, -2.22584635e-01,\n",
       "         1.08810395e-01, -1.76707298e-01, -3.74013931e-02,\n",
       "        -7.32257664e-02,  6.12917803e-02,  3.85168791e-01,\n",
       "         2.20905811e-01,  1.44865036e-01,  1.18731476e-01,\n",
       "        -1.45741612e-01,  1.25688165e-01,  1.59574226e-01,\n",
       "        -1.18297875e-01,  1.34700090e-02,  3.59440029e-01,\n",
       "         1.17220715e-01,  2.71799453e-02,  1.87822625e-01,\n",
       "        -1.53983712e-01,  3.23947042e-01,  3.59169096e-02,\n",
       "        -1.02437437e-01, -1.98501551e+00,  1.76489547e-01,\n",
       "        -1.25898644e-01,  1.17141753e-01, -2.67873649e-02,\n",
       "         1.71596140e-01,  2.61548936e-01, -3.71101871e-02,\n",
       "        -2.67782837e-01, -1.28174707e-01,  3.44860673e-01,\n",
       "        -6.42092973e-02,  1.73110008e-01, -9.43519920e-03,\n",
       "         5.66030070e-02, -1.09270424e-01, -8.16320330e-02,\n",
       "        -1.66186973e-01, -1.92758724e-01, -8.72743428e-02,\n",
       "         2.65949249e-01,  3.90708268e-01, -4.78586890e-02,\n",
       "        -4.31804001e-01, -1.69798657e-01,  2.99638152e-01,\n",
       "         6.47210926e-02, -3.36973071e-01,  1.54781640e-02,\n",
       "        -2.68950760e-02,  3.91762480e-02,  3.00562195e-02,\n",
       "         1.74571276e-01, -6.89237341e-02,  1.29219443e-01,\n",
       "         6.86210990e-02, -8.95464271e-02,  4.48757932e-02,\n",
       "        -7.42844343e-02,  1.29805580e-02, -2.27852941e-01,\n",
       "         1.95264906e-01, -2.33490407e-01,  2.67628759e-01,\n",
       "        -2.02758417e-01,  1.04951821e-01,  2.86518615e-02,\n",
       "        -2.24354595e-01,  2.61003584e-01, -3.33958179e-01,\n",
       "        -2.12966800e-02, -4.95323613e-02,  4.60334539e-01,\n",
       "        -2.51731109e-02,  1.50562763e-01,  2.03501314e-01,\n",
       "         3.42749625e-01,  2.46317178e-01, -6.10003695e-02,\n",
       "        -1.56141341e-01, -4.58989777e-02, -4.29266840e-02,\n",
       "        -3.08866352e-02,  1.16200574e-01,  1.60330728e-01,\n",
       "        -9.76783037e-03, -2.63820648e-01, -1.11186728e-01,\n",
       "        -1.22669660e-01, -9.86203253e-02, -1.45532489e-01,\n",
       "        -8.33305568e-02, -1.35296807e-01,  6.45938069e-02,\n",
       "        -2.89476663e-02,  7.81207979e-02,  3.35547984e-01,\n",
       "         3.70921195e-03,  1.59718618e-01,  2.49109268e-01,\n",
       "         1.35725699e-02, -3.39463592e-01, -3.24519902e-01,\n",
       "        -3.42949361e-01,  4.24900979e-01, -5.39578199e+00,\n",
       "        -1.61571816e-01, -3.60873878e-01, -2.14221880e-01,\n",
       "        -6.85968250e-03, -3.27434957e-01, -1.54970795e-01,\n",
       "        -2.73418039e-01,  9.33999568e-02, -5.63022494e-02,\n",
       "         7.16346055e-02,  5.97540773e-02, -1.10670939e-01,\n",
       "        -1.69523388e-01,  4.42057252e-01,  1.07091025e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] goldberg offers everything look general practitioner nice easy talk without patronizing always time seeing patients affiliated top [SEP]'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.decode(dbert_inp['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape = (max_len,), dtype='int64')\n",
    "    masks= Input(shape = (max_len,), dtype='int64')\n",
    "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
    "    dense = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
    "    dropout= Dropout(0.5)(dense)\n",
    "    pred = Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_2 (TFDisti TFBaseModelOutput(la 66362880    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 768)          0           tf_distil_bert_model_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          393728      tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 649206)       333042678   dropout_58[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 399,799,286\n",
      "Trainable params: 399,799,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    input_ids.append(dbert_inps['input_ids'])\n",
    "    attention_masks.append(dbert_inps['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650000, 650000, 650000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n",
      "Pickle files saved as  ./dbert_inp.pkl ./dbert_mask.pkl ./dbert_label.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./dbert_inp.pkl'\n",
    "pickle_mask_path='./dbert_mask.pkl'\n",
    "pickle_label_path='./dbert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (650000, 32) Attention mask shape (650000, 32) Input label shape (650000,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class_dict={0:'ham',1:'spam'}\n",
    "target_names=label_class_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (520000, 32) Val input shape (130000, 32)\n",
      "Train label shape (520000,) Val label shape (130000,)\n",
      "Train attention mask shape (520000, 32) Val attention mask shape (130000, 32)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))\n",
    "\n",
    "\n",
    "log_dir='dbert_model'\n",
    "model_save_path='./dbert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING (It is taking alot of time on my computer)\n",
    "\n",
    "history=model.fit([train_inp,train_mask],train_label,batch_size=16,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
